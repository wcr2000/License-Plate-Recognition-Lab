{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.7.0\n",
      "CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Setup complete. Using torch {torch.__version__}\")\n",
    "print(torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/watchara/Documents/me/License-Plate-Recognition-Lab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"Working directory:\", HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.143 üöÄ Python-3.13.2 torch-2.7.0 CPU (Apple M4)\n",
      "Setup complete ‚úÖ (10 CPUs, 16.0 GB RAM, 186.2/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/watchara/Documents/me/License-Plate-Recognition-Lab\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 0\n",
      "Class 2: 1\n",
      "Class 3: 2\n",
      "Class 4: 3\n",
      "Class 5: 4\n",
      "Class 6: 5\n",
      "Class 7: 6\n",
      "Class 8: 7\n",
      "Class 9: 8\n",
      "Class 10: 9\n",
      "Class 11: A01\n",
      "Class 12: A02\n",
      "Class 13: A04\n",
      "Class 14: A05\n",
      "Class 15: A06\n",
      "Class 16: A07\n",
      "Class 17: A08\n",
      "Class 18: A09\n",
      "Class 19: A10\n",
      "Class 20: A12\n",
      "Class 21: A13\n",
      "Class 22: A14\n",
      "Class 23: A16\n",
      "Class 24: A18\n",
      "Class 25: A19\n",
      "Class 26: A20\n",
      "Class 27: A21\n",
      "Class 28: A22\n",
      "Class 29: A23\n",
      "Class 30: A24\n",
      "Class 31: A25\n",
      "Class 32: A26\n",
      "Class 33: A28\n",
      "Class 34: A30\n",
      "Class 35: A31\n",
      "Class 36: A32\n",
      "Class 37: A33\n",
      "Class 38: A34\n",
      "Class 39: A35\n",
      "Class 40: A36\n",
      "Class 41: A37\n",
      "Class 42: A38\n",
      "Class 43: A39\n",
      "Class 44: A40\n",
      "Class 45: A41\n",
      "Class 46: A42\n",
      "Class 47: A43\n",
      "Class 48: A44\n",
      "Class 49: ACR\n",
      "Class 50: ATG\n",
      "Class 51: AYA\n",
      "Class 52: BKK\n",
      "Class 53: BKN\n",
      "Class 54: BRM\n",
      "Class 55: BTG\n",
      "Class 56: CBI\n",
      "Class 57: CCO\n",
      "Class 58: CMI\n",
      "Class 59: CNT\n",
      "Class 60: CPM\n",
      "Class 61: CPN\n",
      "Class 62: CRI\n",
      "Class 63: CTI\n",
      "Class 64: KBI\n",
      "Class 65: KKN\n",
      "Class 66: KPT\n",
      "Class 67: KRI\n",
      "Class 68: KSN\n",
      "Class 69: LEI\n",
      "Class 70: LPG\n",
      "Class 71: LPN\n",
      "Class 72: LRI\n",
      "Class 73: MDH\n",
      "Class 74: MKM\n",
      "Class 75: MSN\n",
      "Class 76: NAN\n",
      "Class 77: NBI\n",
      "Class 78: NBP\n",
      "Class 79: NKI\n",
      "Class 80: NMA\n",
      "Class 81: NPM\n",
      "Class 82: NPT\n",
      "Class 83: NSN\n",
      "Class 84: NST\n",
      "Class 85: NYK\n",
      "Class 86: PBI\n",
      "Class 87: PCT\n",
      "Class 88: PKN\n",
      "Class 89: PKT\n",
      "Class 90: PLG\n",
      "Class 91: PLK\n",
      "Class 92: PNA\n",
      "Class 93: PNB\n",
      "Class 94: PRE\n",
      "Class 95: PRI\n",
      "Class 96: PTE\n",
      "Class 97: PTN\n",
      "Class 98: PYO\n",
      "Class 99: RBR\n",
      "Class 100: RET\n",
      "Class 101: RNG\n",
      "Class 102: RYG\n",
      "Class 103: SBR\n",
      "Class 104: SKA\n",
      "Class 105: SKM\n",
      "Class 106: SKN\n",
      "Class 107: SKW\n",
      "Class 108: SNI\n",
      "Class 109: SNK\n",
      "Class 110: SPB\n",
      "Class 111: SPK\n",
      "Class 112: SRI\n",
      "Class 113: SRN\n",
      "Class 114: SSK\n",
      "Class 115: STI\n",
      "Class 116: TAK\n",
      "Class 117: TRG\n",
      "Class 118: TRT\n",
      "Class 119: UBN\n",
      "Class 120: UDN\n",
      "Class 121: UTI\n",
      "Class 122: UTT\n",
      "Class 123: YLA\n",
      "Class 124: YST\n",
      "Total classes: 124\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î YAML ‡πÅ‡∏ö‡∏ö‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "classes_file = \"./LPR/data.yaml\"\n",
    "with open(classes_file, \"r\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á names\n",
    "names = data['names']\n",
    "for idx, name in enumerate(names, start=1):\n",
    "    print(f\"Class {idx}: {name}\")\n",
    "\n",
    "print(\"Total classes:\", len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A28', 'A30', 'A31', 'A32', 'A33', 'A34', 'A35', 'A36', 'A37', 'A38', 'A39', 'A40', 'A41', 'A42', 'A43', 'A44', 'ACR', 'ATG', 'AYA', 'BKK', 'BKN', 'BRM', 'BTG', 'CBI', 'CCO', 'CMI', 'CNT', 'CPM', 'CPN', 'CRI', 'CTI', 'KBI', 'KKN', 'KPT', 'KRI', 'KSN', 'LEI', 'LPG', 'LPN', 'LRI', 'MDH', 'MKM', 'MSN', 'NAN', 'NBI', 'NBP', 'NKI', 'NMA', 'NPM', 'NPT', 'NSN', 'NST', 'NYK', 'PBI', 'PCT', 'PKN', 'PKT', 'PLG', 'PLK', 'PNA', 'PNB', 'PRE', 'PRI', 'PTE', 'PTN', 'PYO', 'RBR', 'RET', 'RNG', 'RYG', 'SBR', 'SKA', 'SKM', 'SKN', 'SKW', 'SNI', 'SNK', 'SPB', 'SPK', 'SRI', 'SRN', 'SSK', 'STI', 'TAK', 'TRG', 'TRT', 'UBN', 'UDN', 'UTI', 'UTT', 'YLA', 'YST']\n",
      "Total classes: 124\n"
     ]
    }
   ],
   "source": [
    "names = data['names']\n",
    "print(names)\n",
    "print(\"Total classes:\", len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train epochs=50 batch=32 imgsz=640 plots=True model= \"./yolov8x.pt\" data= \"./plate_data.yaml\" device=0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.143 üöÄ Python-3.13.2 torch-2.7.0 CPU (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./LPR/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=./LPR/yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/watchara/Documents/me/License-Plate-Recognition-Lab/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=124\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1093876  ultralytics.nn.modules.head.Detect           [124, [64, 128, 256]]         \n",
      "Model summary: 129 layers, 3,353,412 parameters, 3,353,396 gradients, 9.8 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 87.1¬±97.0 MB/s, size: 24.8 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/t\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/3910f48f-a5a8-46c6-bb6f-38ebca66af41_jpg.rf.770d2c7426863ca3ff304cdaf3698f9b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/4140baca-7f3c-4453-bcfa-6af38573e492_jpg.rf.bd86775a670673e740c035557b923d64.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/424da472-ef13-4739-8504-b3ec5c355038_jpg.rf.2146fe9ababc0052a390be321826bae3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/468281f3-4bb5-4ebf-b8aa-ef903ddd3cf6_jpg.rf.930e7423d1252b53fb45feafa003d54b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/47012941-4c6f-4ea3-9f6a-9dea0002886e_jpg.rf.3ad89bc7ea02a9a7bbc99c2e4786a326.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/489d4111-b212-4d5d-83b1-fd82f0073625_jpg.rf.eac999ae6890aba75f6469086b91cddf.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/49111a25-e454-4c5d-901f-fc19f83ada3f_jpg.rf.7948cdaf8d8eaa7063578348beccec48.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/548419aa-c740-4c3b-81f4-7de7f1da04a5_jpg.rf.7d0b443c954e64b1332437a9f12fd8e3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/577b75eb-db89-4f0f-95ca-50691d797320_jpg.rf.6b08011979ce4e23b4786203be782ddc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/5a94ea79-91aa-4e5f-8be4-3e81a0ea2036_jpg.rf.99ea67f32906492dacd43bb97189fd11.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/5ae4f1fc-570a-4106-9bf9-9d57ea1df968_jpg.rf.92bf11e3c6845664cecf1476e0411100.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/5c2a8da2-6656-4a96-90d2-66055814cd73_jpg.rf.85d6e0cd33ff04e77639e4e5a8357275.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/609834ac-dcb6-4600-9d0c-46d3206d94fa_jpg.rf.f7d1e72fac45075e8f85cf773c337487.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/611d4366-f224-457c-b5c0-2b36fdeb4683_jpg.rf.223750e2c4a82ad37bd2b3d560eaf6ab.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/61abf1f9-e5a1-48d2-837a-9e146e6675f9_jpg.rf.4ed48d523d04ec1c818f0f7dc05fc1e0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/627fd2bc-7870-4810-8a38-4d5044345db8_jpg.rf.e4b5849c08bac6a55259c13691061183.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/6322aee6-be7d-4886-8773-395ad178056d_jpg.rf.69b62b0a59340c1c0f92c60e301fd77c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/6b2178d4-c241-4af8-8647-446d445f3c2b_jpg.rf.f3dd25d6174272c56d667a4d5634841a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/6db16d0d-1f6d-4ffb-a665-10f447554f5d_jpg.rf.ebcc152f8ef88b25bf099a3c52c644fc.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/6e499df0-7ad1-42df-8772-d5061245c360_jpg.rf.3dcd51547e8fad9dfcad9b4bc40a9b6a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/71807087-fe38-42f2-8ce1-7f7a0c8037af_jpg.rf.002f871cac247e2e69b6e70d98926874.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/71d7c548-31dd-45de-be2f-aced097d6351_jpg.rf.3988d123317ee7cb2a7d4fda28f61703.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/72c7ff6b-5cae-4fcb-842c-6e71cd18dcaf_jpg.rf.cbb247653b1554942cdae4173c4cedf9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/75006cf3-602b-4091-934a-4b68b1520b11_jpg.rf.6afcaec569a2834a828f31aa10e7b31c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/76aef8f3-89a8-4400-a206-d767bcfacec4_jpg.rf.8a1cdc552b6a525d1297291e7af0010a.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/79ad422e-420d-4843-980c-22987743dbfc_jpg.rf.49616c0968c27766862cf250f5fc14cf.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/7e7716da-f677-43bb-9326-acb29a30e363_jpg.rf.94c443339d7c1b52fe3b1d1551a21971.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/7f29a639-1128-47dd-a7c7-f387cbb2bf0f_jpg.rf.0659f06e4631d5e799ccc714a22a0792.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/7f341df6-914a-403b-ba49-d2ad3f39d0d3_jpg.rf.ca9f6f45291e0b70ac90d2f464d8533c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/80a85f7e-1c67-4df0-92ab-fded29a250fe_jpg.rf.8b0af2b27845686c6fcc2e2323d8b54b.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/81e68ce3-f0a3-46bc-8d81-03988f54b2db_jpg.rf.2a53f4dde534b6552957097b528e2914.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/84187a42-c6f1-4f77-9187-f913152741b2_jpg.rf.76f09b453459e8fd720715b05e4c0fdd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/89cc64f2-ebb7-4111-89f2-48f937e93aa1_jpg.rf.137751e757a8e2cb7d12945dad4a92f1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/8de83adc-834d-4de0-8602-86be7f6b4dea_jpg.rf.0218e199bab38e98d90424962c1bf86e.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/90a57ed0-409b-4868-aa43-37087d16888f_jpg.rf.7f12925877d55597937e474271ee63d7.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/9146810b-0d28-4980-b29c-0cff430d35ca_jpg.rf.fc88b8f30c0360da6e63ecdb35ade2de.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/94206ebf-8ad8-463c-95d6-f737b473c7e6_jpg.rf.1f99f3d9298d64bbd08889b267753b54.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/97a96bb5-5819-4fda-aa49-0fe15b4c3eef_jpg.rf.88d265260cff78c0c996d2234a30be75.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/9d4abad1-a3b2-46d0-a4d5-494e3d5600b7_jpg.rf.6da2448667cf35212554848cc3fbbfcd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/9d89b48d-a936-44f2-96b7-adfcd5fa1ecb_jpg.rf.9045873f4aa59e94384b0a96fe9d0a43.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/9dabf93d-4021-4d39-8d6e-69cbe782c8dc_jpg.rf.cee1994e3cbaf0b2ec85748053e5c546.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/aebbf9d9-4468-472b-af55-241db9bc40b2_jpg.rf.3233ef061aafacefc84cd55902a96e6c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/b1225781-a15c-4e80-a4d2-36c60b0e1e7f_jpg.rf.52161b139138f2868afe96e1abf1c555.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/b702889e-17f2-4a13-b6a3-7e5533a031fb_jpg.rf.c7d93f907ba4c3eefbfc8e682581c4df.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/c06956b1-48bb-4e4d-aae7-415fc26abdc3_jpg.rf.e6838824026c46b77ccc8131c9900bd1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/c31486fa-f917-46f2-b92c-cac2b6f146dd_jpg.rf.34aee2bb7529e0b22b84af54aa60de38.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/c907abdd-42d8-4f6d-8727-5bac977c9006_jpg.rf.6343fda34f3637734c0cdf1b900f44b7.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/train/images/c9637e05-02be-4e4e-a95b-6605fbed13e8_jpg.rf.db0262b55fe0b43ad40c098322a9d298.jpg: 1 duplicate labels removed\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 227, len(boxes) = 59862. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 22.1¬±8.9 MB/s, size: 5.6 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/val\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/valid/images/111bb263-8577-4a8a-96c9-a91fc55f7610_jpg.rf.87552d92d471835f29d9e80276402050.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/valid/images/13ffd473-0c3c-4c62-a14f-d2afd19ad80b_jpg.rf.f434c134e2e7d6d5a3e6adecbddff1c4.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/valid/images/163676b8-9a85-4923-a4e0-dd9c8b7c0a60_jpg.rf.30cd85da26f3ce12ae03df2586bd4327.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/valid/images/23dd7f13-3397-4b85-bc82-420d03c8ed42_jpg.rf.8c1b4b4ad7a2d4be02462c8bab70ebc9.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/valid/images/25cec407-b3ff-4ca9-8bee-630c32700795_jpg.rf.f73c6aaa8e18fb1e82b6c471afcb2b65.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/LPR/valid/images/2933deb5-0055-4502-b070-897f857b4470_jpg.rf.35ff1c71e924928c17e5e76968e3daca.jpg: 1 duplicate labels removed\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 30, len(boxes) = 7131. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to /Users/watchara/Documents/me/License-Plate-Recognition-Lab/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=7.8e-05, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/watchara/Documents/me/License-Plate-Recognition-Lab/runs/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50         0G          1      4.043      1.075        182        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        999       7131      0.806      0.104      0.126      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G      0.746      1.426     0.9752        222        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        999       7131      0.669      0.256      0.249      0.213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G     0.6797      1.024     0.9378        442        640:  ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/bin/yolo\", line 8, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/cfg/__init__.py\", line 981, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/engine/model.py\", line 796, in train\n",
      "    self.trainer.train()\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/engine/trainer.py\", line 390, in _do_train\n",
      "    loss, self.loss_items = self.model(batch)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/nn/tasks.py\", line 114, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/nn/tasks.py\", line 313, in loss\n",
      "    preds = self.forward(batch[\"img\"]) if preds is None else preds\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/nn/tasks.py\", line 115, in forward\n",
      "    return self.predict(x, *args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/nn/tasks.py\", line 133, in predict\n",
      "    return self._predict_once(x, profile, visualize, embed)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/nn/tasks.py\", line 156, in _predict_once\n",
      "    x = m(x)  # run\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/ultralytics/nn/modules/head.py\", line 73, in forward\n",
      "    x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py\", line 240, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/Users/watchara/Documents/me/License-Plate-Recognition-Lab/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=50 batch=32 imgsz=640 plots=True model= \"./LPR/yolov8n.pt\" data= \"./LPR/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo task=detect mode=train model=runs/detect/train6/weights/last.pt resume=True epochs=50 batch=32 imgsz=640 device=0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
